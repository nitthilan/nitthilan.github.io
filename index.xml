<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Nitthilan</title>
    <link>https://nitthilan.github.io/</link>
      <atom:link href="https://nitthilan.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Nitthilan</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>nitthilan@gmail.com</copyright><lastBuildDate>Wed, 01 Jan 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://nitthilan.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Nitthilan</title>
      <link>https://nitthilan.github.io/</link>
    </image>
    
    <item>
      <title>Design and Optimization of Energy-Accuracy Tradeoff Networks for Mobile Platforms via Pretrained Deep Models</title>
      <link>https://nitthilan.github.io/publication/jayakodi-2020-design/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://nitthilan.github.io/publication/jayakodi-2020-design/</guid>
      <description></description>
    </item>
    
    <item>
      <title>GRAMARCH: A GPU-ReRAM based Heterogeneous Architecture for Neural Image Segmentation</title>
      <link>https://nitthilan.github.io/publication/joardar-2020-gramarch/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://nitthilan.github.io/publication/joardar-2020-gramarch/</guid>
      <description></description>
    </item>
    
    <item>
      <title>PETNet: Polycount and Energy Trade-off Deep Networks for Producing 3D Objects from Images</title>
      <link>https://nitthilan.github.io/publication/jayakodi-2020-petnet/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://nitthilan.github.io/publication/jayakodi-2020-petnet/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Uncertainty-Aware Search Framework for Multi-Objective Bayesian Optimization.</title>
      <link>https://nitthilan.github.io/publication/belakaria-2020-uncertainty/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://nitthilan.github.io/publication/belakaria-2020-uncertainty/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Active Anomaly Detection via Ensembles: Insights, Algorithms, and Interpretability</title>
      <link>https://nitthilan.github.io/publication/das-2019-active/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://nitthilan.github.io/publication/das-2019-active/</guid>
      <description></description>
    </item>
    
    <item>
      <title>MOOS: A multi-objective design space exploration and optimization framework for NoC enabled manycore systems</title>
      <link>https://nitthilan.github.io/publication/deshwal-2019-moos/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://nitthilan.github.io/publication/deshwal-2019-moos/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Trading-off Accuracy and Energy of Deep Inference on Embedded Systems: A Co-Design Approach</title>
      <link>https://nitthilan.github.io/publication/kannappan-2019-trading/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://nitthilan.github.io/publication/kannappan-2019-trading/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Active anomaly detection via ensembles</title>
      <link>https://nitthilan.github.io/publication/das-2018-active/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://nitthilan.github.io/publication/das-2018-active/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Trading-off accuracy and energy of deep inference on embedded systems: A co-design approach</title>
      <link>https://nitthilan.github.io/publication/jayakodi-2018-trading/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://nitthilan.github.io/publication/jayakodi-2018-trading/</guid>
      <description></description>
    </item>
    
    <item>
      <title>AI Resources (Under Development)</title>
      <link>https://nitthilan.github.io/ai_resource/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://nitthilan.github.io/ai_resource/</guid>
      <description>&lt;h6 id=&#34;sections&#34;&gt;Sections&lt;/h6&gt;
&lt;p&gt;&lt;a href=&#34;#about&#34;&gt;About&lt;/a&gt; - &lt;a href=&#34;#significant-areas&#34;&gt;Significant Areas&lt;/a&gt;-&lt;a href=&#34;#current-task-list&#34;&gt;Current Task List&lt;/a&gt; - &lt;a href=&#34;#tutorials&#34;&gt;Tutorials&lt;/a&gt; - &lt;a href=&#34;#applications&#34;&gt;Applications&lt;/a&gt; - &lt;a href=&#34;#prominent-papers&#34;&gt;Prominent Papers&lt;/a&gt;&lt;/p&gt;
&lt;h6 id=&#34;about&#34;&gt;About&lt;/h6&gt;
&lt;p&gt;Inspired from Pixar, Dreamworks, Sony and other animation studios. The general time required to produce an animated feature from conception to final rendered version has a long production time.
Can Artificial Intelligence based solutions help in reducing this time line?&lt;/p&gt;
&lt;p&gt;The current advancements in deep learning in the area of GAN, Neural Rendering help to automate many processes like creating 3D models, animating 3d model motion.&lt;/p&gt;
&lt;p&gt;Project Ideas : &lt;a href=&#34;#multi-view-based-3d-models&#34;&gt;Multi view based 3D models&lt;/a&gt; - Virtual Studio - Human Models&lt;/p&gt;
&lt;h6 id=&#34;multi-view-based-3d-models&#34;&gt;Multi view based 3D models&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;Neural Fields Rendering System:
Requirements:
&lt;ul&gt;
&lt;li&gt;Store objects as neural network
&lt;ul&gt;
&lt;li&gt;It could be a single neural network for each object&lt;/li&gt;
&lt;li&gt;multiple obejcts encoded in the same network using embedding as input.&lt;/li&gt;
&lt;li&gt;Store embeedding for each voxel and a common neural network. A generalized marching cubes algorithm.&lt;/li&gt;
&lt;li&gt;A hybrid progressive representation
&lt;ul&gt;
&lt;li&gt;A global embedding for overall structure and progressive embedding for successive voxel breaking to refine the shape to increased quality&lt;/li&gt;
&lt;li&gt;DeepLS, SDF (It has a different embedding compared to NSVF). It tried to learn NN to learn smaller edges. Heirarchical NeRF -&amp;gt; NSVF&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Can transformer networks be used instead of NN?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Learning material properties: &lt;a href=&#34;https://github.com/bmild/nerf/issues/23&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nerf Issues&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Looks like there is a solution which uses Albedo and Illumination in CVPR. Environment maps are used to replicate theillumination problem&lt;/li&gt;
&lt;li&gt;Light could be used as a dot product i.e. a NN which takes the direction of light, direction of incident ray and material properties at that point and produces the output at that point&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;current-task-list&#34;&gt;Current Task List&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Modify NSVF - embedding and voxel culling&lt;/li&gt;
&lt;li&gt;Modify NeRF - to support SDF experiments&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;list-of-ideas&#34;&gt;List of ideas:&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;SDF helps in physics based simulations i.e. they help in contact detection between objects and hence in object object touching etc - so may help in hair, cloth simulations
&lt;ul&gt;
&lt;li&gt;Experiment with Occupancy and SDF variations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Can we split objects into separate objects which and then join them together later [Graffe paper]. Create a system which can align objects as different poses and translation and camera pose&lt;/li&gt;
&lt;li&gt;Use Nerf++ to encode forground and background object&lt;/li&gt;
&lt;li&gt;NeRF for Human shapes: Fashion related human modeling design and animation.
&lt;ul&gt;
&lt;li&gt;Garment Hair 3D geometry and charater animation.&lt;/li&gt;
&lt;li&gt;Nerf setup for hair and cloth simulation. Interpreenetation of hair strands into head and sholder&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Learn a prior using NeRF and learn embeddings using a single input image [PiFU].
&lt;ul&gt;
&lt;li&gt;Used trained NN and extract embeddings based on input image. Heirarchical NerF -&amp;gt; NSVF&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Can Embedding be learnt for different parts like face, hands clothers. Can we use Pose as input - CPIGAN
&lt;ul&gt;
&lt;li&gt;Using PSNR or SSIM to identify areas in the learnt model which are not properly learnt and using this guide the rays to be used for learning.
&lt;ul&gt;
&lt;li&gt;Create a weigting map of the areas which are lacking detail&lt;/li&gt;
&lt;li&gt;Sample rays based on this weighting map within a picture&lt;/li&gt;
&lt;li&gt;Sample rays based on weighting map of all the pictures&lt;/li&gt;
&lt;li&gt;Split voxels adaptively based on the PSNR and SSIM distribution&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Progressively learning model using smaller images and gradually increasing the image dimension as we increase the model accuracy. The aim is to reduce the training time of the 3D model.
&lt;ul&gt;
&lt;li&gt;Estimating the bounding box automatically based on the camera position&lt;/li&gt;
&lt;li&gt;Use images from smaller size along widthxheight probably rations 2,4,8&lt;/li&gt;
&lt;li&gt;Select a small subset of camera postions to start with and gradually increase with iterations&lt;/li&gt;
&lt;li&gt;Allocate initial voxel size based on all the camera postions and interpixel ray distance and then as the image dimensions increase the voxel size would decrease accordingly&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Culling Voxels - This reduces the number voxels used for representing the object. This helps in reduction of the memory .Voxels in the bounding box which are not touched by the rays. Two major regions
&lt;ul&gt;
&lt;li&gt;Voxels inside the object which are not reached by the rays&lt;/li&gt;
&lt;li&gt;Voxels outside the object region which are not touched by the training rays&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;NeRF in Motion: Encoding motion for objects in a neural scene. There are diffferent ideas for it.
&lt;ul&gt;
&lt;li&gt;Using normalized coordinate system i.e. map actual values to normalised value to then learn a warping function which adds on to it and then render it f(X(x), Y(y), Z(z)). Maps (x,y,z) for each time step. Learn how bones are mapped to mesh pixels. Find the transformation function) - Motion Capture based rendering system
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2011.12948.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deformable Neural Radiance Fields&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2011.12950.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Space-time Neural Irradiance Fields for Free-Viewpoint Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;NSVF uses Hyper networks to encode every network encode for each time step. &lt;a href=&#34;https://arxiv.org/pdf/1906.01618.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SRN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Like mesh objects, can Bones, rigging and weighting be added for the objects thereby making it configurable &lt;a href=&#34;https://www.peachpit.com/articles/article.aspx?p=483793&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bone structure&lt;/a&gt;, &lt;a href=&#34;https://blog.machinimatrix.org/avastar/features/rigging-and-weighting/3/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Blog&lt;/a&gt;,&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Few Shot Learning:
&lt;ul&gt;
&lt;li&gt;Learning priors using bayesian neural networks: &lt;a href=&#34;https://en.wikipedia.org/wiki/Uncertainty_quantification&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Uncertainity Quantification&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/1505.05424&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Weight Uncertainity in NN&lt;/a&gt;, &lt;a href=&#34;http://krasserm.github.io/2019/03/14/bayesian-neural-networks/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Variational Inference in Bayesian NN&lt;/a&gt; - The idea is to train priors of shapes using neural networks and then try to learn the representation using a single image input. The prior stores range of uncertainity in the variance of the weights and tries to find the right instance value using a single image input. We try to replace a NN in NeRF to a Baysian NN and try to model the uncertainity in shape as the weights of the bayesian-neural-networks&lt;/li&gt;
&lt;li&gt;Understanding GPT3: &lt;a href=&#34;https://arxiv.org/pdf/2005.14165.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://openai.com/blog/better-language-models/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GPT2 Blog&lt;/a&gt;, &lt;a href=&#34;https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GPT2 Paper&lt;/a&gt;, &lt;a href=&#34;https://www.youtube.com/watch?v=_8yVOC4ciXc&amp;amp;ab_channel=Computerphile&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Youtube&lt;/a&gt;, &lt;a href=&#34;https://www.youtube.com/watch?v=SY5PvZrJhLE&amp;amp;ab_channel=YannicKilcher&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Youtube2&lt;/a&gt;,&lt;/li&gt;
&lt;li&gt;Transformers for 3d model - &lt;a href=&#34;https://papers.nips.cc/paper/6206-perspective-transformer-nets-learning-single-view-3d-object-reconstruction-without-3d-supervision.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Perspective Transformer Nets&lt;/a&gt;, &lt;a href=&#34;http://proceedings.mlr.press/v97/lee19d/lee19d.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Set Transformer&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/pdf/1906.10887.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Spatial Transformer for 3D Point Clouds&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://leggedrobotics.github.io/rl-blindloco/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Possible continous learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Active learning for 3d object reconstruction&lt;/li&gt;
&lt;li&gt;Structure from motion using deep learning: &lt;a href=&#34;https://www.robots.ox.ac.uk/~vgg/publications/1998/Fitzgibbon98a/fitzgibbon98a.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Turntable&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Can NeRF be modeled to run without the camera parameters? Since we are modelling the neural network as a funtioin of x,y,z can we learn using SGD the model without the camera parameters?&lt;/li&gt;
&lt;li&gt;Fix one camera position. Model the 3D model as function of relative camera parrameter. Try minimising the error of images while we learn the error from different projections.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Code list:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/shunsukesaito/PIFu&#34;&gt;https://github.com/shunsukesaito/PIFu&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/pifuhd&#34;&gt;https://github.com/facebookresearch/pifuhd&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kwea123/nerf_pl&#34;&gt;https://github.com/kwea123/nerf_pl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/NSVF&#34;&gt;https://github.com/facebookresearch/NSVF&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;prominent-papers&#34;&gt;Prominent Papers&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/list/cs.CV/pastweek?show=490&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Arxiv - Computer Vision&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://scholar.google.com/scholar?cites=9378169911033868166&amp;amp;as_sdt=5,48&amp;amp;sciodt=0,48&amp;amp;hl=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nerf - citations&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://scholar.google.com/scholar?cites=8122086353742917335&amp;amp;as_sdt=5,48&amp;amp;sciodt=0,48&amp;amp;hl=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NSVF - citations&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis: &lt;a href=&#34;https://arxiv.org/pdf/2003.08934.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;paper&lt;/a&gt;, &lt;a href=&#34;https://github.com/kwea123/nerf_pl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code&lt;/a&gt;, &lt;a href=&#34;https://github.com/kwea123/nerf_pl/blob/master/README_mesh.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;mesh reconstruction&lt;/a&gt;, &lt;a href=&#34;https://github.com/bmild/nerf/issues/44&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;color reproduction&lt;/a&gt;, &lt;a href=&#34;https://github.com/pmneila/PyMCubes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PyMcubes&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Neural Sparse Voxel Fields: &lt;a href=&#34;https://arxiv.org/pdf/2007.11571.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains: &lt;a href=&#34;https://arxiv.org/pdf/2006.10739.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Generating Diverse High-Fidelity Images with VQ-VAE-2: &lt;a href=&#34;https://arxiv.org/pdf/1906.00446.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections: &lt;a href=&#34;https://arxiv.org/pdf/2008.02268.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Neural Rendering: &lt;a href=&#34;https://github.com/weihaox/awesome-neural-rendering&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;project&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/Kai-46/nerfplusplus&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nerf++&lt;/a&gt; - &lt;a href=&#34;https://arxiv.org/pdf/2010.07492.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://research.fb.com/wp-content/uploads/2020/05/FroDO-From-Detections-to-3D-Objects.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;FroDo&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2004.00452.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PIFuHD&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/1905.05172.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PIFu&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://storage.googleapis.com/nerfies-public/videos/nerfies_paper.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deformable Neural Radiance Fields&lt;/a&gt; - &lt;a href=&#34;https://nerfies.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;project&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://proceedings.mlr.press/v80/bojanowski18a/bojanowski18a.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Optimizing the Latent Space of Generative Networks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2011.12950.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Space-time Neural Irradiance Fields for Free-Viewpoint Video&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2011.13961.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;D-NeRF: Neural Radiance Fields for Dynamic Scenes&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2011.12100.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GIRAFFE: Representing Scenes as Compositional Generative Neural Feature Fields&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cvlibs.net/publications/Schwarz2020NEURIPS.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GRAF&lt;/a&gt; - &lt;a href=&#34;https://avg.is.tuebingen.mpg.de/publications/schwarz2020neurips&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;project&lt;/a&gt; - &lt;a href=&#34;https://github.com/autonomousvision/graf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2011.12490.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DeRF: Decomposed Radiance Fields&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://demuc.de/papers/schoenberger2016sfm.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SFM - Structure from motion&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://openaccess.thecvf.com/content_CVPR_2019/papers/Park_DeepSDF_Learning_Continuous_Signed_Distance_Functions_for_Shape_Representation_CVPR_2019_paper.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DeepSDF&lt;/a&gt; - &lt;a href=&#34;https://github.com/facebookresearch/DeepSDF&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Code&lt;/a&gt; - &lt;a href=&#34;https://openaccess.thecvf.com/content_CVPR_2019/supplemental/Park_DeepSDF_Learning_Continuous_CVPR_2019_supplemental.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Supp&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2008.02268.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nerf-W&lt;/a&gt; - Nerf in the wild&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://papers.nips.cc/paper/2019/file/b5dc4e5d9b495d0196f61d45b26ef33e-Paper.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2004.03805.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;State of the Art on Neural Rendering&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/google/ldif&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Local Deep Implicit Functions for 3D Shape&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2011.13650.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deformed Implicit Field: Modeling 3D Shapes with Learned Dense Correspondence&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;canonical coordinates 3d model, quaternion representation of rotation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://jamie-wong.com/2016/07/15/ray-marching-signed-distance-functions/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ray marching and sdf&lt;/a&gt; - &lt;a href=&#34;https://www.cl.cam.ac.uk/teaching/1819/FGraphics/1.%20Ray%20Marching%20and%20Signed%20Distance%20Fields.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SDF renderiing&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;AI Sculptor: Assuming the rays as a nail, we like to sculpt a 3D model based on multiple input views. We use the NSVF as our based code. The list of problems we are planning to attack:
- Marching cubes would fail to recover the surface since the function learns only the boundary and does not learn inside the object. So a different learning algorithm is required for learning the 3D mesh object. We need to find a better algorithm to extract the 3D mesh and surface information.
- A soluttion would be to shoot rays from different directions and choose only those points which have normals which are parallel to the ray of intersection. Use these points as an input to creat a point cloud and then convert this point cloud to a mesh using &lt;a href=&#34;https://towardsdatascience.com/5-step-guide-to-generate-3d-meshes-from-point-clouds-with-python-36bad397d8ba&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pointcloud2mesh&lt;/a&gt; algorithms, &lt;a href=&#34;https://www.cgal.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Surface Reconstruction&lt;/a&gt;
- Alternative representation: Signed Distance field representation has better representation of objects than transparency representation. Can we use SDF instead of transparency? Define a rendering function using SDF. Use this function instead of transparency based rendering function and then use it to represent Neural scene &lt;a href=&#34;https://openaccess.thecvf.com/content_CVPR_2019/papers/Park_DeepSDF_Learning_Continuous_Signed_Distance_Functions_for_Shape_Representation_CVPR_2019_paper.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DeepSDF&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/pdf/2003.10983.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DeepLS&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/pdf/1802.05384.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Papier-Machˆe&lt;/a&gt;, &lt;a href=&#34;https://openaccess.thecvf.com/content_CVPR_2019/papers/Mescheder_Occupancy_Networks_Learning_3D_Reconstruction_in_Function_Space_CVPR_2019_paper.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Occupancy Networks&lt;/a&gt;
- Heirarchical representation: Nerf/DeepSDF use NN to represent the whole scene. NSVF/DeepLS use local embedding information to represent shapes in voxels. Can a heirarchchical representation of latent variables be used to represnet the whole shape to get consistent representation.
- Can the shape information used as code in DeepSDF be used in NERF/NSVF kind of setup to reduce the number of images to encode a scene directly from a siingle image
- Physics simulation using NeRF: &lt;a href=&#34;https://users.cg.tuwien.ac.at/zsolnai/gfx/fluid_control_msc_thesis/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Real Time Fluid simulation&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/pdf/2002.09405.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Learning to simulate&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A algorithm to solve generic problems: &lt;a href=&#34;https://xinyazhang.gitlab.io/puzzletunneldiscovery/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;C-Space Tunnel Discovery for Puzzle Path Planning&lt;/a&gt;, &lt;a href=&#34;https://gitlab.com/xinyazhang/puzzle-geometry/-/tree/master/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;More Puzzles&lt;/a&gt;, &lt;a href=&#34;https://xinyazhang.gitlab.io/puzzletunneldiscovery/assets/MainPaper.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;paper&lt;/a&gt; - Concentrate on the different planning algorithms. The baisc idea would be to find tunnels (i.e. narrow points which could possibly leead to a solution). Then have a duble tree starting from Start and reversely from goal. This could be done for every tunnel point. This stage is the blooming stage. You could approximate the value of the tree using neural networks. Try finding links from the bloomed tree and the successive tunnel paths. IF we find a route find the optimal route from start to end - Probabilistic Roadmap Path Planning &lt;a href=&#34;http://www.cs.columbia.edu/~allen/F15/NOTES/Probabilisticpath.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PRM Planner&lt;/a&gt;, &lt;a href=&#34;https://people.eecs.berkeley.edu/~pabbeel/cs287-fa11/slides/MotionPlanning-v1.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PRM1&lt;/a&gt;, &lt;a href=&#34;http://planning.cs.uiuc.edu/node772.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RDT-Based Methods&lt;/a&gt; - dual-tree RDT algorithm&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;significant-areas&#34;&gt;Significant Areas&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;Bayesian Optimzation based GAN latent variable search&lt;/li&gt;
&lt;li&gt;Bayesian Neural network based BO&lt;/li&gt;
&lt;li&gt;StyleGAN&lt;/li&gt;
&lt;li&gt;Camera pose estimate&lt;/li&gt;
&lt;li&gt;Fourier feature networks&lt;/li&gt;
&lt;li&gt;Photogrammetry - &lt;a href=&#34;https://all3dp.com/1/best-photogrammetry-software/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;software&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Part segmentation&lt;/li&gt;
&lt;li&gt;HairNet&lt;/li&gt;
&lt;li&gt;Sculpting&lt;/li&gt;
&lt;li&gt;SMPL&lt;/li&gt;
&lt;li&gt;Image Harmonization&lt;/li&gt;
&lt;li&gt;Pose Transfer&lt;/li&gt;
&lt;li&gt;Multi-view rendering&lt;/li&gt;
&lt;li&gt;HyperNetworks&lt;/li&gt;
&lt;li&gt;Continous Learning - &lt;a href=&#34;https://imirzadeh.me/#contact&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Iman&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/pdf/2006.06958.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;paper&lt;/a&gt;, &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0893608019300231&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Review Paper&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/pdf/2007.00487.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tackling catastropic forgetting&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/pdf/2004.00713.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Incremental learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/timzhang642/3D-Machine-Learning&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;3D Machine Learning Github&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;to-be-read-papers&#34;&gt;To Be Read Papers&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://ondrejtexler.github.io/patch-based_training/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Interactive Video StylizationInteractive Video Stylization&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/pdf/2010.05334.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Resolution Dependent GAN&lt;/a&gt;, &lt;a href=&#34;http://chengao.vision/FGVC/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Video Completion&lt;/a&gt;,&lt;a href=&#34;https://arxiv.org/pdf/1707.05776.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Latent Space of Generative Networks&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/pdf/1703.04977.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bayesian Deep Learning for Computer Vision&lt;/a&gt;, &lt;a href=&#34;https://genforce.github.io/idinvert/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Real Image Editing GAN&lt;/a&gt;, &lt;a href=&#34;https://rewriting.csail.mit.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Rewriting a Deep Generative Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Softwares: &lt;a href=&#34;https://www.synthesia.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AI Vdo&lt;/a&gt;, &lt;a href=&#34;https://www.cinetracer.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CineTracer&lt;/a&gt;,&lt;a href=&#34;https://vast.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GPU Sharing&lt;/a&gt;,&lt;a href=&#34;https://www.spyfu.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SpyFU&lt;/a&gt;, &lt;a href=&#34;https://obsproject.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OBS Studio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://research.fb.com/wp-content/uploads/2020/06/Neural-Supersampling-for-Real-time-Rendering.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Neural Sampling&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;current-task-list-1&#34;&gt;Current Task List&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;tutorials&#34;&gt;Tutorials&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;GAN basics,&lt;/li&gt;
&lt;li&gt;Running models on GPU&lt;/li&gt;
&lt;li&gt;Framework - Pytorch, Keras, numpy, Pytorch3D&lt;/li&gt;
&lt;li&gt;AlphaZero,&lt;/li&gt;
&lt;li&gt;CPISADGAN&lt;/li&gt;
&lt;li&gt;BO&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/DeepRobot2020/books/blob/master/Multiple%20View%20Geometry%20in%20Computer%20Vision%20%28Second%20Edition%29.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MultiView Geometry&lt;/a&gt;, &lt;a href=&#34;http://ksimek.github.io/2012/08/14/decompose/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Camera Basics&lt;/a&gt;, &lt;a href=&#34;https://mathworld.wolfram.com/RotationMatrix.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Rotation Matrix&lt;/a&gt;, &lt;a href=&#34;http://robotics.stanford.edu/~birch/projective/node2.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Projective, Affine, Euclidean Geometry&lt;/a&gt;, &lt;a href=&#34;https://learnopengl.com/Getting-started/Coordinate-Systems&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NDC Co-ordinate Systems&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;applications&#34;&gt;Applications&lt;/h6&gt;
&lt;h6 id=&#34;graphics-related&#34;&gt;Graphics related&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.nvidia.com/en-us/design-visualization/omniverse/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Omniverse&lt;/a&gt;, &lt;a href=&#34;https://mmacklin.com/sdfcontact.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Signed Distance Field Collision&lt;/a&gt;, &lt;a href=&#34;http://rgl.epfl.ch/publications/Zeltner2020Specular&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Specular Manifold Sampling&lt;/a&gt;, &lt;a href=&#34;https://matthias-research.github.io/pages/publications/PBDBodies.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Detailed Rigid Body Simulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Character creation: &lt;a href=&#34;https://www.reallusion.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Reallusion&lt;/a&gt;, &lt;a href=&#34;https://www.mixamo.com/fuse/1.3/eol&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Adobe Fuse/Mixamo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;sections-1&#34;&gt;Sections&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;#children-resources&#34;&gt;Children resources&lt;/a&gt; - &lt;a href=&#34;#videos&#34;&gt;Videos&lt;/a&gt; - &lt;a href=&#34;#accelerators&#34;&gt;Accelerators&lt;/a&gt; - &lt;a href=&#34;#channels-followed&#34;&gt;Channels followed&lt;/a&gt; - &lt;a href=&#34;#gpu-and-cuda-resource&#34;&gt;GPU and CUDA resource&lt;/a&gt; - &lt;a href=&#34;#projects&#34;&gt;Projects&lt;/a&gt;&lt;/p&gt;
&lt;h6 id=&#34;tutorials-1&#34;&gt;Tutorials&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aipaygrad.es/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AI pay grades&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;children-resources&#34;&gt;Children resources&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://ecraft2learn.github.io/ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ecraft2learn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.media.mit.edu/posts/kids-ai-devices/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;mit&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://machinelearningforkids.co.uk/#!/links#top&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;machinelearningforkids&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;videos&#34;&gt;Videos&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=dmkPJpWCVcI&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Heroes of Deep Learning: Andrew Ng interviews Pieter Abbeel&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=St5lxIxYGkI&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deepmind opensources starcraft II ai&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=cLC_GHZCOVQ&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenAI bots beats DOTA Worl champion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=_aUq7lmMfxo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deepmind and UCL course work&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;list-of-topics-to-be-covered&#34;&gt;List of topics to be covered&lt;/h6&gt;
&lt;h6 id=&#34;good-resources&#34;&gt;Good resources&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://incompleteideas.net/sutton/book/the-book-2nd.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sutton Book&lt;/a&gt;: &lt;a href=&#34;http://incompleteideas.net/sutton/book/bookdraft2016sep.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Book Draft&lt;/a&gt;, &lt;a href=&#34;https://github.com/ShangtongZhang/reinforcement-learning-an-introduction&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Code And Examples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=2pWv7GOvuf0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deep Mind: RL Course by David Silver&lt;/a&gt; - First of a 10 lecture series - &lt;a href=&#34;http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html&#34;&gt;http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;accelerators&#34;&gt;Accelerators&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://betalist.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;betalist&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://angel.co/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;angel&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.crunchbase.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;crunchbase&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.producthunt.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;producthunt&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.startupschool.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;startupschool&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://disneyaccelerator.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;disneyaccelerator&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;job-options&#34;&gt;Job Options&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://e3expo.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;E3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://cvpr2020.thecvf.com/jobs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CVPR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://s2020.siggraph.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Siggraph&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ctnanimationexpo.com/index.php&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;cartoon network animation expo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;internships&#34;&gt;Internships&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;Studio list - Pixar, nickelodean, laika, dreamworks, bluesky, warner brothers, cartoon network, Blizzard&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=44DdiybwJ8c&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;How to get a pixar internship&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.animationcareerreview.com/articles/walt-disney-animation-studios-career-profile#:~:text=According%20to%20the%20company%20website,Maya%20or%20a%20similar%20program.&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Animation colleges&lt;/a&gt; - &lt;a href=&#34;http://conceptdesignacad.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;conceptdesignacad&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=dY-Ts69F4Xo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;How to get a job at Blizzard&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;portfolio-creation&#34;&gt;Portfolio creation&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.deviantart.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DevianArt&lt;/a&gt;, Instagram, YouTube&lt;/li&gt;
&lt;li&gt;List of inspiring artists: bobby pontillas, rafael grassetti &lt;a href=&#34;https://gumroad.com/grassettiart&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;human anatomy&lt;/a&gt;, &lt;a href=&#34;https://www.youtube.com/watch?v=VmUikhiWu8c&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;youtube&lt;/a&gt;, Laura Price &lt;a href=&#34;https://www.youtube.com/watch?v=lfZ8HKUhxak&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MY ART JOURNEY&lt;/a&gt;, &lt;a href=&#34;https://www.youtube.com/watch?v=dY-Ts69F4Xo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Michael Vicente&lt;/a&gt;, &lt;a href=&#34;https://www.youtube.com/channel/UCLEVrhumRsK67JkP3G4w5cQ/videos&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ross draws&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://polycount.com/forum&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Polycount&lt;/a&gt;, &lt;a href=&#34;https://www.zbrushcentral.com/t/gallery/227023&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;zbrush central&lt;/a&gt;, &lt;a href=&#34;https://www.artstation.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;artstation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Books - &lt;a href=&#34;https://www.amazon.com/dp/B00LKL6Q3S/ref=dp-kindle-redirect?_encoding=UTF8&amp;amp;btkr=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Composing Pictures&lt;/a&gt;, &lt;a href=&#34;https://www.amazon.com/Illusion-Life-Disney-Animation/dp/0786860707&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;illusion of life&lt;/a&gt;, &lt;a href=&#34;https://www.amazon.com/Animators-Survival-Kit-Expanded-Principles/dp/0571238343&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Animators survival kit&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;channels-followed&#34;&gt;Channels followed&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://deepai.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DeepAI: The front page of A.I.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://madewithml.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Made With ML&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;gpu-and-cuda-resource&#34;&gt;GPU and CUDA resource&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/accelerated-computing-instances.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AWS&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;p2 - NVIDIA Tesla K80 - 2 x 2496&lt;/li&gt;
&lt;li&gt;G3 - NVIDIA Tesla M60 - 4096 NVIDIA CUDA® cores (2048 per GPU)&lt;/li&gt;
&lt;li&gt;G2 - NVIDIA GRID K520 GPUs - 3072 core&lt;/li&gt;
&lt;li&gt;CG1 -  NVIDIA Tesla M2050&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://developer.nvidia.com/academic_gpu_seeding&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NVIDIA Grant&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NVIDIA Quadro M5000 - 2048 [GeForce Titan Xp, Quadro P5000, NVIDIA M5000 specification]&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.nvidia.com/en-us/geforce/products/10series/geforce-gtx-1080-ti/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GTX 1080i&lt;/a&gt; - 3584 - 700$&lt;/li&gt;
&lt;li&gt;GTX 1080 - 2,560 - 500$&lt;/li&gt;
&lt;li&gt;GTX 1070 - 1920 - 390&lt;/li&gt;
&lt;li&gt;Titan X pascal - 3584&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.phoronix.com/scan.php?page=article&amp;amp;item=jetson-tegra-x2&amp;amp;num=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jetson&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;EGPU: &lt;a href=&#34;https://egpu.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;egpu&lt;/a&gt;, &lt;a href=&#34;https://9to5mac.com/2017/04/11/hands-on-powering-the-macbook-pro-with-an-egpu-using-nvidias-new-pascal-drivers/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;9to5mac&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Fun</title>
      <link>https://nitthilan.github.io/entertainment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://nitthilan.github.io/entertainment/</guid>
      <description>&lt;h3 id=&#34;sections&#34;&gt;Sections&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;#drawing&#34;&gt;Drawing&lt;/a&gt; - &lt;a href=&#34;#movies&#34;&gt;Movies&lt;/a&gt; - &lt;a href=&#34;#short-stories-tamil&#34;&gt;Short Stories (Tamil)&lt;/a&gt; - &lt;a href=&#34;#investment&#34;&gt;Investment&lt;/a&gt; - &lt;a href=&#34;#cooking&#34;&gt;Cooking&lt;/a&gt; - &lt;a href=&#34;#writing&#34;&gt;Writing&lt;/a&gt; - &lt;a href=&#34;#motivation&#34;&gt;Motivation&lt;/a&gt; - &lt;a href=&#34;#food&#34;&gt;Food&lt;/a&gt; - &lt;a href=&#34;#stories&#34;&gt;Stories&lt;/a&gt;&lt;/p&gt;
&lt;h5 id=&#34;drawing&#34;&gt;Drawing&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://i.ytimg.com/vi/ZUCHi_2ncPQ/maxresdefault.jpg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Girl on mooon&lt;/a&gt; - &lt;a href=&#34;https://www.youtube.com/watch?v=ZUCHi_2ncPQ&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;youtube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;motivation&#34;&gt;Motivation&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;The motivation comes after work and not the other way around.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://youtu.be/bAmXn1fWnpE?t=6614&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jigarthanda&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;If you want to go fast go alone, if you want to go far, go together&lt;/li&gt;
&lt;li&gt;When you have many things to do pick the most important and most interesting at that point to work and start working&lt;/li&gt;
&lt;li&gt;&amp;ldquo;He sought many things from the act of terror but one was notoriety. And that is why you will never hear me mention his name. He is a terrorist. He is a criminal. He is a extremist.  But he will when I speak be nameless&amp;rdquo; - Jacinda Ardern&lt;/li&gt;
&lt;li&gt;&amp;ldquo;You have to establish who you are in this world. Donot let others establish who you are&amp;rdquo; - Madonna to Rodman&lt;/li&gt;
&lt;li&gt;MJordan - Do as many things as possible and do not be lazy&lt;/li&gt;
&lt;li&gt;Pursue things which make you happy. Do not do things which make you sad&lt;/li&gt;
&lt;li&gt;Think of solutions of problems which are imminent. Do not think of imaginary problems.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=WPPPFqsECz0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;An Antidote to Dissatisfaction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://matthewjohnstone.com.au/courses/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;I had a black dog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Caste - &lt;a href=&#34;https://www.youtube.com/watch?v=PZb4lGYkjrg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;India untouched&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;movies&#34;&gt;Movies&lt;/h5&gt;
&lt;h5 id=&#34;series&#34;&gt;Series&lt;/h5&gt;
&lt;h6 id=&#34;amazon-prime&#34;&gt;Amazon Prime&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/gp/video/detail/B0886H18DR/ref=atv_wl_hom_c_unkc_1_1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paatal Lok&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/gp/video/detail/B07TT23VHY/ref=atv_wl_hom_c_unkc_1_5&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Comicstaan&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/gp/video/detail/B07WSD8XWF/ref=atv_wl_hom_c_unkc_1_15&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Marvelous Mrs. Maisel&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/gp/video/detail/B07SQB8LQ9/ref=atv_wl_hom_c_unkc_1_16&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Undone&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/gp/video/detail/B079TKQV8H/ref=atv_wl_hom_c_unkc_1_22&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Remix&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/gp/video/detail/B000WCT7M8/ref=atv_wl_hom_c_unkc_1_43&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;House&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/gp/video/detail/B07YCV6LCJ/ref=atv_wl_hom_c_unkc_1_8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Goliath&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/gp/video/detail/B0064MGU98/ref=atv_wl_hom_c_unkc_1_30&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Good Wife&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/gp/video/detail/B07C2M2YPJ/ref=atv_wl_hom_c_unkc_1_23&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Killing Eve&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/gp/video/detail/B07GBGZW55/ref=atv_wl_hom_c_unkc_1_39&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Harmony with A R Rahman&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/gp/video/detail/B074XLMGBQ/ref=atv_wl_hom_c_unkc_1_44&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mr. Bean&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;netflix&#34;&gt;Netflix&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.netflix.com/title/80212245&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Dragon Prince&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.netflix.com/title/80165295&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Misaeng&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.netflix.com/title/80153467&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Unbelievable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.netflix.com/title/80192098&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Money Heist&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;songs&#34;&gt;Songs&lt;/h6&gt;
&lt;h5 id=&#34;short-stories-tamil&#34;&gt;Short Stories (Tamil)&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.valaitamil.com/literature_short-story&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;valaitamil&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.sramakrishnan.com/?cat=85&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;sramakrishnan&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://azhiyasudargal.blogspot.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;azhiyasudargal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.sirukathaigal.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;sirukathaigal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.quora.com/What-are-the-best-Tamil-sites-to-read-short-stories&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;What-are-the-best-Tamil-sites-to-read-short-stories&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ta.wikisource.org/wiki/%E0%AE%AE%E0%AF%81%E0%AE%A4%E0%AE%B1%E0%AF%8D_%E0%AE%AA%E0%AE%95%E0%AF%8D%E0%AE%95%E0%AE%AE%E0%AF%8D&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wiki&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.quora.com/What-are-the-best-short-stories-in-Tamil&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;What-are-the-best-short-stories-in-Tamil&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Dostoevsky, Tolstoy - totally 7 books&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;food&#34;&gt;Food&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://youtu.be/iatPAjf5I_Y&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Intermittent fasting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://youtu.be/uV_orGyIfGw&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Myth about fruits&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Almonds, Egg, Spinach,&lt;/li&gt;
&lt;li&gt;Carrot,&lt;/li&gt;
&lt;li&gt;Pudina, Garlic, Pattai/Lavangam(), Murungai illai&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;investment&#34;&gt;Investment&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.fool.com/investing/how-to-invest-in-value-stocks.aspx&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;how-to-invest-in-value-stocks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.fool.com/investing/growth-investing-step-by-step-guide.aspx&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;growth-investing-step-by-step-guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.fool.com/earnings-call-transcripts/?page=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;earnings-call-transcripts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.fool.com/investing/2020/03/08/3-top-tech-stocks-to-buy-right-now.aspx&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;3-top-tech-stocks-to-buy-right-now&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;understanding a company performance for investment&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;cooking&#34;&gt;Cooking&lt;/h5&gt;
&lt;h6 id=&#34;sweet&#34;&gt;Sweet&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=Y5v_65iXpY0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kesari&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=5_cIM4PGd2U&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paayasam&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=hkTAMlLcN2c&amp;amp;list=PL4mtHuMZdZjwUYR38YGrLMTlOgW-W3b6B&amp;amp;index=19&amp;amp;t=9s&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Date Paayasam&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Wheat halwa: &lt;a href=&#34;https://www.youtube.com/watch?v=Gya1J-mGHBM&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ast but may not be that good&lt;/a&gt;, &lt;a href=&#34;https://www.youtube.com/watch?v=oG7wglvAXeg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Looks too good. In Tamil&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=oHSNGbSQlDE&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Moong dal payasam&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;The great baking show : Netflix show: Cakes, Biscuits are a good to do bayesian experiments, cookies&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;non-veg&#34;&gt;Non-veg&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;Biriyani Options: &lt;a href=&#34;https://www.youtube.com/watch?v=Sj6mM6IXAq8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Chicken&lt;/a&gt;, &lt;a href=&#34;https://www.youtube.com/watch?v=uQqwj9um9_g&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cooker Egg Biriyani&lt;/a&gt;, &lt;a href=&#34;https://www.youtube.com/watch?v=5VapbxkA_UA&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;biriyani egg&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=JAVbJf3o3qk&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prawn Fry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=sUkt91x-cOY&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Fish Fry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=h_qsg8Gof4Q&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Brinjal gravy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=upfu5nQB2ks&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Chicken tikka masala&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=LtPu6Jd-ZhI&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Butter masala&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=X_idvqxRD3E&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;spanish omlete&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Frittata&lt;/li&gt;
&lt;li&gt;Egg roll wrapper and make samosa&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=KatLap0bLmo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Egg malai masala&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Uppu kari : mutton receipie - looks awesome&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;veg&#34;&gt;Veg&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=J3tCBVTgzLg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;chinese dishes like noodles etc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=aM_wiQFia2M&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;paneer masala&lt;/a&gt;, &lt;a href=&#34;https://www.youtube.com/watch?v=eDOmZPQns8M&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;mattar paneer - looks better. besan&lt;/a&gt;, &lt;a href=&#34;https://www.youtube.com/watch?v=_Um-jLO7_bM&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;paneer tikka masala&lt;/a&gt;, &lt;a href=&#34;https://www.youtube.com/watch?v=1mVP2TkjafI&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;paneer butter masala&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://delightfulvegetarianrecipes.com/category/healthy/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prashant recipes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;writing&#34;&gt;Writing:&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;English speaking &lt;a href=&#34;https://www.youtube.com/watch?v=r_5K7cs24-8&amp;amp;list=PL4IJAxR6Bqq8vP0kEeQRgU6lUe4s4u2DW&amp;amp;index=4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link1&lt;/a&gt;, &lt;a href=&#34;https://www.youtube.com/watch?v=QTJ02h7uiXs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Learn English in 3 Hours - ALL You Need to Master English Conversation&lt;/a&gt;, &lt;a href=&#34;https://www.youtube.com/watch?v=6DiQ95hUUfI&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;American accent&lt;/a&gt;, &lt;a href=&#34;http://dl.ueb.edu.vn/bitstream/1247/2927/1/American%20Accent%20Training.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;American Accent1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.writersbeat.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;writersbeat&lt;/a&gt;,&lt;a href=&#34;https://www.writingforums.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;writingforums&lt;/a&gt;, &lt;a href=&#34;https://nybookeditors.com/2015/11/11-top-writing-communities-you-should-join-and-why/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;nybookeditors&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;books-to-read&#34;&gt;Books to read&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;communist manifesto, rights of man thomas paine&lt;/li&gt;
&lt;li&gt;THE ANNIHILATION OF CASTE - &lt;a href=&#34;file:///Users/kannappanjayakodinitthilan/Downloads/aoc_print_2004.pdf&#34;&gt;text&lt;/a&gt;, &lt;a href=&#34;https://soundcloud.com/freebuddhistaudio/sets/annihilation-of-caste&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;soundcloud&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;stories&#34;&gt;Stories&lt;/h5&gt;
&lt;p&gt;&lt;a href=&#34;#my-brother&#34;&gt;My brother&lt;/a&gt;&lt;/p&gt;
&lt;h6 id=&#34;my-brother&#34;&gt;My brother&lt;/h6&gt;
&lt;p&gt;As I stood there waiting for the bus/plane to arrive, my thouhgts dragged me to the past. Its been a while. It was one of those days. You have been thinking of saying something to your parents but did not have the confidence to talk about it. It was not different for a girl in here ninth grade.&lt;/p&gt;
&lt;p&gt;My artificial deadline was before the van arrives for the school that day. I want to vent it all out on my parents.&lt;/p&gt;
&lt;p&gt;&amp;ldquo;Kanna, are you out of your bed. Its getting late for school.&amp;rdquo; Amma/Mom gave morning alert. Mickey was licking my feet. She curled down at my feet after her morning ritual of dropping the newspaper at my fathers bedside. &amp;ldquo;Han, Ma. I am up.&amp;rdquo;  If not next she would be up in my room banging the door. This is her alarm. She is the final failsafe alarm when all alarms fail. Probably thats true about life too. Not sure. Parents.&lt;/p&gt;
&lt;p&gt;It all started few months back as a joke. As usual, I did not finish my lunch. &amp;ldquo;Yaen di. Innaikuma. Everyday this has becoma habit. If this carries on, I will sell you and get a new kid&amp;rdquo; &amp;ldquo;Try it. You never know. I may get better parents. or worse you may get even fussy brother&amp;rdquo; &amp;ldquo;Why brother? You do not like a sister.&amp;rdquo; &amp;ldquo;There could never be a better girl than me&amp;rdquo; &amp;ldquo;Fine. Atleast have dinner now. We will decide your auction date after a while&amp;rdquo;&lt;/p&gt;
&lt;p&gt;I slowly walked to the bathroom, reluctantly. One, I hate my science teacher and her so called surprise tests scheduled today. Two, I was not sure how I am going to share my thoughts with my parents. My brush poking its way around my mouth as I ruminate on these thoughts. Standing under the shower, I felt the water was cold today. Probably it would rain and the school would get cancelled. &amp;ldquo;Anju, Can you hurry up a little? Its getting late for my office&amp;rdquo; Appa knocked on my door. I can hear Mickey too scratching the door. Stepping out I thought I should go through all I wanted to talk once again as I dressed up. Today it PT class. I have to wear white today. As I stepped out of my room, amma had already prepared the lunch. Appa was also ready to leave for office. I sat on the couch, my throne. Appa was at my feet dusting my socks and cleaning my shoes. Amma came with dosa on the plate ready to stuff it in my mouth before I run away to catch the van. there was a 5 minute gap. The right time. &amp;ldquo;Appa, is it necessary to bring in a yonger brother&amp;rdquo; Appa paused a little &amp;ldquo;Yaen ma, why this question suddenly?&amp;rdquo; Amma, dipped a piece of dosa in sambar and as it dripped on the plate &amp;ldquo;Solluma. What are your thoughts?&amp;rdquo; &amp;ldquo;Illa ma. I am not feeling comfortable.&amp;rdquo; Appa dropped the shoes and took me on his lap and with a concerned face &amp;ldquo;Solluda. Why do you feel uncomfortable&amp;rdquo; &amp;ldquo;You said, two days back during dinner that you are planning to have sibling.&amp;rdquo; &amp;ldquo;Hmmm&amp;rdquo; Amma fed a socked dosa in my mounth. &amp;ldquo;Are you worried that you will have a competition.&amp;rdquo; &amp;ldquo;Do not worry da. I will clean both your shoes.&amp;rdquo; With a muffled voice of dosa in mouth &amp;ldquo;Unhun. Thats not a issue. Is it necesary to bring a new sibling?&amp;rdquo; &amp;ldquo;Ennada sollura. I am not able to understand what you are saying?&amp;rdquo; &amp;ldquo;Illa pa. Last year. On the way to Raju Sithappa place, it was raining heavily and we hit a dog by accident.&amp;rdquo; &amp;ldquo;Sari. Amma, Thats were we found mickey. She came limping towards us.&amp;rdquo; &amp;ldquo;Athan pa solluren. Last Sunday when we were sitting on the beach, there was a small kid selling Sundal. Why cannot he be my sibling?&amp;rdquo; Appa smiled. Amma fed the last piece of dosa and I rushed for the van.
My phone vibrated, breaking my thought process. &amp;ldquo;Hey Anju, where are you?&amp;rdquo; &amp;ldquo;Vaada. Just walk outside and walk towards the taxi stand.&amp;rdquo; If not for that day, I would not have met Koushik, my brother.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
